# 预期学习线路

1.  **理论先行**：对于 Transformer 的每一个组件（从 `Linear` 开始），我首先会结合课程讲义 (`cs336_spring2025_assignment1_basics.pdf`)，为您讲解：
    * 这个组件在 Transformer 模型中的**作用和目的**是什么？
    * 它的**数学原理**或定义是什么？（例如 `Linear` 就是矩阵乘法 $y=Wx$）
    * 讲义中提到的**关键要求或约束**是什么？（例如 `Linear` 不能有偏置项，权重初始化规则）
    * 为什么会有这些设计选择？（如果讲义或常识中有解释）

2.  **代码印证**：在您理解了理论之后，我们再来看“优秀代码”（`hw1-basics/scripts/model.py`）中对应的实现。我会逐行或逐段分析代码，向您展示理论是如何被转换成具体的 PyTorch 代码的，以及代码是如何满足讲义中的要求的。

3.  **动手实践（可选）**：如果您愿意，在理解了理论和代码后，您可以尝试自己重新实现一遍，或者对现有代码做一些小的修改来验证理解。

**整体学习路线**：

我们将按照讲义 第 3 节的顺序，逐个攻克 Transformer 的组件：

* **基础构建块**：
    * `Linear` 模块 (理论 -> 代码)
    * `Embedding` 模块 (理论 -> 代码)
* **Transformer Block 内部组件**：
    * `RMSNorm` 模块 (理论 -> 代码)
    * Position-Wise Feed-Forward Network (`SwiGLU`) (理论 -> 代码)
    * Rotary Position Embeddings (`RoPE`) (理论 -> 代码)
    * `softmax` 函数 (理论 -> 代码)
    * Scaled Dot-Product Attention (理论 -> 代码)
    * Causal Multi-Head Self-Attention (理论 -> 代码)
* **组装**：
    * `TransformerBlock` (理论 -> 代码)
    * 完整的 `BasicsTransformerLM` (理论 -> 代码)

我觉得这个“理论 -> 代码”的路线非常好，能确保您不仅会写代码，更明白代码背后的原理。

那么，我们就从 **`Linear` 模块的理论知识**开始讲解，您觉得怎么样？

